{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9cc31ad",
   "metadata": {},
   "source": [
    "# PySpark series from ***Krish Naik***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa7875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b287ed0c",
   "metadata": {},
   "source": [
    "How can we use spark with Python?\n",
    "For this we have library calles as PySpark\n",
    "\n",
    "It's use for preprocessing\n",
    "\n",
    "how to use in cloud\n",
    "\n",
    "It's simple\n",
    "\n",
    "Fast 100x as compare to pandas\n",
    "\n",
    "#Use\n",
    "Suppose you have 8 gb ram system but data that you want to use is 65 gb so what you do?\n",
    "For this kind of problem pyspark come into the picture\n",
    "\n",
    "Also have mlib for machine learning library\n",
    "\n",
    "We can perform work into distribution of system\n",
    "\n",
    "before this we useing map reduce(spark is much faster than map reduce)\n",
    "\n",
    "It's run on cluster mode\n",
    "\n",
    "It's built on the top of Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485b5192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4efe16c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Krish</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sudhansh</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Age\n",
       "0     Krish   31\n",
       "1  Sudhansh   30\n",
       "2     Sunny   29"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to read in pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.read_csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7939da1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ebcda6e",
   "metadata": {},
   "source": [
    "# In Spark\n",
    "\n",
    "First of all we have to start a **Spark Session**\n",
    "\n",
    "Note- make sure you have java in your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4087bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86c32059",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark= SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "426fc4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-DMATGTD:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x182fc2b7c50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9c7b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('test1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "516e97ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It's only gives you column name with it's default type as string\n",
    "\n",
    "#Automatically gives you c0 and c1 column name\n",
    "\n",
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c60c1b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|     _c0|_c1|\n",
      "+--------+---+\n",
      "|    Name|Age|\n",
      "|   Krish| 31|\n",
      "|Sudhansh| 30|\n",
      "|   Sunny| 29|\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To show the data\n",
    "\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ad47128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|    Name|Age|\n",
      "+--------+---+\n",
      "|   Krish| 31|\n",
      "|Sudhansh| 30|\n",
      "|   Sunny| 29|\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To read file column as column name in spark\n",
    "\n",
    "df_pyspark= spark.read.option('header','true').csv('test1.csv')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "010c470e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type of data frame in pyspark\n",
    "\n",
    "type(df_pyspark)\n",
    "\n",
    "#It's an SQL dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99dd8c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Krish', Age='31'),\n",
       " Row(Name='Sudhansh', Age='30'),\n",
       " Row(Name='Sunny', Age='29')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Head Working\n",
    "# In pyspark head with take only one row by default\n",
    "\n",
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2997541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To see the Schema(same as df.info())\n",
    "\n",
    "df_pyspark.printSchema()\n",
    "\n",
    "#As you can see both are string so as per rule age shoul be integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e56a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c55041f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79682916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea8c2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c86e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172fcf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e1919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
