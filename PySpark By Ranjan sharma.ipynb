{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e469484d",
   "metadata": {},
   "source": [
    "# Big Data?\n",
    "\n",
    "5 Hints for big data: \n",
    "\n",
    "1) Volume : The size of data\n",
    "\n",
    "2) Velocity : The speed at which data is generated\n",
    "\n",
    "3) Variety : The different type of data ()\n",
    "\n",
    "4) Veracity : The trustworthiness of data\n",
    "\n",
    "5) Value : Just having Big Data is no use unleass we can turn it into Value\n",
    "\n",
    "\n",
    "\n",
    "# Big Data vs Hadoop\n",
    "\n",
    "Big data is the problem whereas Hadoop is the solution\n",
    "To overcome from big data problem we use Hadoop.\n",
    "\n",
    "\n",
    "**Hadoop**\n",
    "\n",
    "Google launch a system----- GFS(Google file system), In which files were stored in distributed manner.\n",
    "After some google has released a Map Reduce System(but they didn't include GFS)\n",
    "\n",
    "\n",
    "Then After some time **Yahoo** lauch a new system ***Hadoop*** and it's map and resuce system.\n",
    "\n",
    "Hadoop architecture look like below : \n",
    "\n",
    "HDFS      ----------------------->            Map Reduce                -------------------------->  YARN\n",
    "\n",
    "\n",
    "1) HDFS : (Storage Unit) Hadoop distributed file system. It shows in which format data is stored.\n",
    "           It partitate tha data in multiple partition depends on the size of data\n",
    "\n",
    "2) Map Reduce :  (Compute Engine), \n",
    "                  Map- It's a operation which perform parralerly on the small datadets\n",
    "                  Reduce - It combine all the results\n",
    "                  \n",
    "3) YARN :  (Resource Manager).\n",
    "           In Version 1 yarn was not available but from version2 it's available\n",
    "           Yarn divide the task for each task\n",
    "          \n",
    "\n",
    " \n",
    "**After finding some issues in hadoop ApacheSpark come into the picture**\n",
    "\n",
    "Map resuce is replaced by Spark\n",
    "\n",
    "# Apcake Spark\n",
    "\n",
    "So Map reduce is replaced by **Apache spark**\n",
    "\n",
    "HDFS -- In place of HDFS now we can use **CSV, Excel, amazon S3 storage etc.**\n",
    "\n",
    "Yarn--- In Pleace of yarn we use Spark internal resourse manager.\n",
    "        We can use kubernets, mesos, yarn etc.\n",
    "        \n",
    "        \n",
    "        \n",
    "**Data Cycle**\n",
    "\n",
    "Source------> Ingest-------> Process---------> Store---------> Serve Data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Hadoop is use for batch processing and can not use forstream data\n",
    "\n",
    "It's become tough\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97106d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36bf3d5a",
   "metadata": {},
   "source": [
    "# Second Video\n",
    "\n",
    "Spark is computine engine and written in **Scala**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38b307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd69104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a7f0f16",
   "metadata": {},
   "source": [
    "\n",
    "# Pandas vs Spark\n",
    "\n",
    "\n",
    "PySpark use PY4j(Python for java)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
